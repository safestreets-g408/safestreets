{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from transformers import BertTokenizer, BertModel"
      ],
      "metadata": {
        "id": "g5iWMXAfzk7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"alvarobasily/road-damage\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rI1jpMmtzlhL",
        "outputId": "57226cd4-3eb9-456a-9003-e2c5559c77be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/road-damage\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_path):\n",
        "  image_files = []\n",
        "  text_files = []\n",
        "  for filename in os.listdir(data_path):\n",
        "          if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\"jpeg\"):\n",
        "              image_files.append(os.path.join(data_path, filename))\n",
        "          elif filename.endswith(\".txt\"):\n",
        "              text_files.append(os.path.join(data_path, filename))\n",
        "  return image_files, text_files"
      ],
      "metadata": {
        "id": "zLdazq-NzpUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_path = \"/kaggle/input/road-damage\"\n",
        "#images, txt = load_data(data_path)"
      ],
      "metadata": {
        "id": "DXRSzhXe0SlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_damage_info(txt_file_path):\n",
        "    with open(txt_file_path, 'r') as file:\n",
        "        line = file.readline().strip()\n",
        "        parts = line.split()\n",
        "        if len(parts) >= 5: # check if the file has the correct number of values.\n",
        "            class_id = int(parts[0])\n",
        "            coordinates = [float(val) for val in parts[1:]]\n",
        "            return class_id, coordinates\n",
        "        else:\n",
        "          return None, None\n",
        "\n",
        "#for i in range(5):\n",
        "    #print(extract_damage_info(txt[i]))"
      ],
      "metadata": {
        "id": "kUEAFBuT0inU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image_path):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    img_tensor = preprocess(img).unsqueeze(0)\n",
        "    return img_tensor\n",
        "\n",
        "#processed_img = process_image(images[0])\n",
        "#processed_img, processed_img.shape"
      ],
      "metadata": {
        "id": "LlmpZf6b02QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RoadDamageClassifier(nn.Module):\n",
        "    def __init__(self, vit_model, num_classes, coordinate_dim=4, output_dim=256):\n",
        "        super(RoadDamageClassifier, self).__init__()\n",
        "        self.vit = vit_model\n",
        "        self.vit.heads = nn.Identity()\n",
        "        self.image_projection = nn.Linear(self.vit.hidden_dim, output_dim)\n",
        "        self.coordinate_projection = nn.Linear(coordinate_dim, output_dim)\n",
        "        self.combined_projection = nn.Linear(output_dim * 2, output_dim)\n",
        "        self.classifier = nn.Linear(output_dim, num_classes)\n",
        "\n",
        "    def forward(self, image, coordinates):\n",
        "        image_features = self.vit(image)\n",
        "        image_projected = self.image_projection(image_features)\n",
        "\n",
        "        coordinate_projected = self.coordinate_projection(coordinates)\n",
        "        combined_features = torch.cat((image_projected, coordinate_projected), dim=1)\n",
        "        combined_projected = self.combined_projection(combined_features)\n",
        "\n",
        "        class_output = self.classifier(combined_projected)\n",
        "        return class_output"
      ],
      "metadata": {
        "id": "3WGACPWX27Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = ViT_B_16_Weights.DEFAULT\n",
        "vit_model = vit_b_16(weights=weights)\n",
        "vit_model.eval()\n",
        "\n",
        "num_classes = 4\n",
        "model = RoadDamageClassifier(vit_model, num_classes)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtVpfw-R3AkK",
        "outputId": "3e57f7ac-de86-4af7-b9d8-f09adb587bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RoadDamageClassifier(\n",
              "  (vit): VisionTransformer(\n",
              "    (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "    (encoder): Encoder(\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "      (layers): Sequential(\n",
              "        (encoder_layer_0): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_1): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_2): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_3): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_4): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_5): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_6): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_7): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_8): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_9): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_10): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (encoder_layer_11): EncoderBlock(\n",
              "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (self_attention): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): MLPBlock(\n",
              "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.0, inplace=False)\n",
              "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (4): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    )\n",
              "    (heads): Identity()\n",
              "  )\n",
              "  (image_projection): Linear(in_features=768, out_features=256, bias=True)\n",
              "  (coordinate_projection): Linear(in_features=4, out_features=256, bias=True)\n",
              "  (combined_projection): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (classifier): Linear(in_features=256, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/root/.cache/kagglehub/datasets/alvarobasily/road-damage/versions/1\"\n",
        "images, txt = load_data(path)"
      ],
      "metadata": {
        "id": "ATSCzae7AN6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class RoadDamageDataset(Dataset):\n",
        "    def __init__(self, image_files, text_files, transform=None):\n",
        "        self.image_files = image_files\n",
        "        self.text_files = text_files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        txt_path = self.text_files[idx]\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        class_id, coordinates = extract_damage_info(txt_path)\n",
        "        coordinates = torch.tensor(coordinates, dtype=torch.float32)\n",
        "\n",
        "        return image, coordinates, class_id"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8p_Yyjqa-5t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = RoadDamageDataset(images, txt, transform=transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "]))\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "images, coordinates, labels = train_loader.__iter__().__next__()\n",
        "images, coordinates, labels"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZFCKMHCl-6fS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b33d91b-b24d-488f-d062-e5fb40821f6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[-0.0458, -0.1486, -0.1314,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-0.0287, -0.1657, -0.2171,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-0.1314, -0.2342, -0.1143,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           ...,\n",
              "           [ 0.2796,  0.2796,  0.2796,  ...,  0.5536,  0.5536,  0.5364],\n",
              "           [ 0.3138,  0.3309,  0.3138,  ...,  0.5364,  0.5193,  0.5022],\n",
              "           [ 0.2967,  0.2967,  0.2967,  ...,  0.5364,  0.5364,  0.5022]],\n",
              " \n",
              "          [[ 0.3978,  0.4328,  0.4503,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [ 0.4503,  0.4503,  0.4153,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [ 0.3452,  0.3452,  0.5203,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           ...,\n",
              "           [ 0.3803,  0.3627,  0.3627,  ...,  0.6779,  0.6604,  0.6604],\n",
              "           [ 0.3978,  0.3803,  0.3452,  ...,  0.6604,  0.6604,  0.6429],\n",
              "           [ 0.3803,  0.3627,  0.3627,  ...,  0.6604,  0.6604,  0.6429]],\n",
              " \n",
              "          [[ 0.1825, -0.0441, -0.0964,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [ 0.2173, -0.0790, -0.2358,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [ 0.1128, -0.0790, -0.0790,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           ...,\n",
              "           [ 0.3916,  0.3916,  0.3916,  ...,  0.7925,  0.7751,  0.7402],\n",
              "           [ 0.4439,  0.4439,  0.4265,  ...,  0.7751,  0.7576,  0.7228],\n",
              "           [ 0.4439,  0.4439,  0.4265,  ...,  0.7751,  0.7751,  0.7228]]],\n",
              " \n",
              " \n",
              "         [[[ 2.1975,  2.1975,  2.1975,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [ 2.1975,  2.1975,  2.1975,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [ 2.1975,  2.1975,  2.1975,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           ...,\n",
              "           [-0.2856, -0.2856, -0.2684,  ..., -0.1657, -0.1657, -0.1657],\n",
              "           [-0.2684, -0.2684, -0.2513,  ..., -0.1486, -0.1486, -0.1828],\n",
              "           [-0.2684, -0.2513, -0.2513,  ..., -0.0458, -0.1143, -0.0972]],\n",
              " \n",
              "          [[ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           ...,\n",
              "           [-0.1450, -0.1450, -0.1275,  ..., -0.0749, -0.0574, -0.0574],\n",
              "           [-0.1275, -0.1275, -0.1099,  ..., -0.0574, -0.0399, -0.0749],\n",
              "           [-0.1275, -0.1099, -0.1099,  ...,  0.0476, -0.0224, -0.0049]],\n",
              " \n",
              "          [[ 2.5703,  2.5703,  2.5703,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [ 2.5703,  2.5703,  2.5703,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [ 2.5703,  2.5703,  2.5703,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           ...,\n",
              "           [-0.0267, -0.0267, -0.0092,  ..., -0.0441, -0.0267, -0.0267],\n",
              "           [-0.0267, -0.0267,  0.0082,  ..., -0.0441, -0.0092, -0.0441],\n",
              "           [-0.0441, -0.0267, -0.0092,  ...,  0.0431, -0.0092,  0.0082]]],\n",
              " \n",
              " \n",
              "         [[[ 2.1975,  2.1975,  2.1975,  ...,  2.1804,  2.1290,  1.4612],\n",
              "           [ 2.1975,  2.1975,  2.1975,  ...,  2.1633,  2.1290,  1.9235],\n",
              "           [ 2.1975,  2.1975,  2.1975,  ...,  1.8379,  1.9064,  1.4440],\n",
              "           ...,\n",
              "           [-0.7650, -1.0048, -1.1932,  ...,  0.1597,  0.2111,  0.2111],\n",
              "           [-1.2617, -1.3302, -1.3473,  ...,  0.2453,  0.2111,  0.1939],\n",
              "           [-1.2617, -1.2103, -1.1075,  ...,  0.1768,  0.2111,  0.2111]],\n",
              " \n",
              "          [[ 2.4111,  2.4111,  2.4111,  ...,  2.4286,  2.3585,  1.6933],\n",
              "           [ 2.4111,  2.4111,  2.4111,  ...,  2.4111,  2.3936,  2.1835],\n",
              "           [ 2.4111,  2.4111,  2.4111,  ...,  2.0784,  2.1835,  1.7108],\n",
              "           ...,\n",
              "           [-0.6702, -0.8803, -1.0378,  ...,  0.2052,  0.2577,  0.2577],\n",
              "           [-1.1253, -1.1779, -1.1779,  ...,  0.2927,  0.2577,  0.2402],\n",
              "           [-1.0553, -1.0378, -0.9853,  ...,  0.2052,  0.2402,  0.2402]],\n",
              " \n",
              "          [[ 2.5703,  2.5703,  2.5703,  ...,  2.5703,  2.5180,  1.8383],\n",
              "           [ 2.5703,  2.5703,  2.5703,  ...,  2.5354,  2.5703,  2.3611],\n",
              "           [ 2.5703,  2.5703,  2.5703,  ...,  2.1868,  2.3088,  1.8731],\n",
              "           ...,\n",
              "           [-0.5844, -0.7761, -0.9504,  ...,  0.0953,  0.1476,  0.1476],\n",
              "           [-1.0201, -1.0550, -1.0550,  ...,  0.1651,  0.1476,  0.1302],\n",
              "           [-0.9330, -0.8807, -0.8110,  ...,  0.0779,  0.1302,  0.1302]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[-0.8507, -0.8849, -0.8335,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-1.1075, -0.7822, -0.7822,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-1.0219, -0.8335, -0.8849,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           ...,\n",
              "           [-0.3883, -0.4226, -0.4226,  ...,  0.0227,  0.0227,  0.0056],\n",
              "           [-0.3541, -0.3369, -0.3027,  ...,  0.0227,  0.0398,  0.0398],\n",
              "           [-0.3541, -0.3369, -0.2856,  ...,  0.0227,  0.0227,  0.0398]],\n",
              " \n",
              "          [[-0.4951, -0.4951, -0.3901,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [-0.7402, -0.3901, -0.3375,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [-0.6352, -0.4076, -0.4601,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           ...,\n",
              "           [-0.4426, -0.4601, -0.4601,  ...,  0.1001,  0.1001,  0.0826],\n",
              "           [-0.4076, -0.3901, -0.3550,  ...,  0.1001,  0.1176,  0.1176],\n",
              "           [-0.4076, -0.3901, -0.3375,  ...,  0.1001,  0.1001,  0.1176]],\n",
              " \n",
              "          [[-0.5844, -0.6715, -0.6715,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [-0.7413, -0.4973, -0.5321,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [-0.6018, -0.4973, -0.5147,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           ...,\n",
              "           [-0.4275, -0.4624, -0.4798,  ...,  0.2173,  0.1999,  0.1825],\n",
              "           [-0.3927, -0.3753, -0.3404,  ...,  0.2173,  0.2173,  0.2173],\n",
              "           [-0.3927, -0.3578, -0.3404,  ...,  0.2348,  0.2173,  0.2173]]],\n",
              " \n",
              " \n",
              "         [[[-0.4226, -0.0629, -0.4226,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-0.4054, -0.4739, -0.6452,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-0.7308, -0.5253, -0.5938,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           ...,\n",
              "           [-1.0048, -0.9877, -0.9877,  ...,  0.4337,  0.4337,  0.3994],\n",
              "           [-0.7479, -0.7308, -0.7137,  ...,  0.4508,  0.4166,  0.4166],\n",
              "           [-0.4568, -0.4226, -0.3883,  ...,  0.4337,  0.4166,  0.3994]],\n",
              " \n",
              "          [[-0.1275,  0.2927, -0.0924,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [-0.1099, -0.1275, -0.3375,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [-0.4076, -0.2150, -0.3025,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           ...,\n",
              "           [-0.7577, -0.7577, -0.7227,  ...,  0.5903,  0.5903,  0.5553],\n",
              "           [-0.5126, -0.4951, -0.4601,  ...,  0.6078,  0.5728,  0.5728],\n",
              "           [-0.1975, -0.1800, -0.1625,  ...,  0.5728,  0.5553,  0.5553]],\n",
              " \n",
              "          [[-0.7413, -0.4450, -0.7238,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [-0.6715, -0.8284, -0.9156,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           [-0.9156, -0.7064, -0.6715,  ...,  2.5703,  2.5703,  2.5703],\n",
              "           ...,\n",
              "           [-0.4450, -0.4450, -0.4275,  ...,  0.7228,  0.7228,  0.6879],\n",
              "           [-0.2358, -0.2358, -0.2184,  ...,  0.7402,  0.7054,  0.7054],\n",
              "           [ 0.0256,  0.0605,  0.0605,  ...,  0.7228,  0.6879,  0.6879]]],\n",
              " \n",
              " \n",
              "         [[[-1.0219, -1.0048, -0.8164,  ...,  2.1975,  2.1975,  2.1975],\n",
              "           [-0.9705, -1.0219, -0.8507,  ...,  2.0605,  2.0263,  1.9578],\n",
              "           [-0.8849, -0.9705, -0.8335,  ...,  1.4098,  1.1015,  1.3755],\n",
              "           ...,\n",
              "           [-0.3883, -0.3712, -0.3712,  ...,  0.2967,  0.2967,  0.2796],\n",
              "           [-0.1999, -0.1999, -0.1999,  ...,  0.2967,  0.2796,  0.2796],\n",
              "           [-0.0287, -0.0287, -0.0287,  ...,  0.2796,  0.2796,  0.2796]],\n",
              " \n",
              "          [[-0.7402, -0.7052, -0.5126,  ...,  2.4111,  2.4111,  2.4111],\n",
              "           [-0.7052, -0.7402, -0.5476,  ...,  2.2710,  2.2710,  2.2185],\n",
              "           [-0.6176, -0.6877, -0.5476,  ...,  1.6408,  1.3957,  1.7108],\n",
              "           ...,\n",
              "           [-0.1625, -0.1450, -0.1450,  ...,  0.4678,  0.4678,  0.4503],\n",
              "           [-0.0224, -0.0049, -0.0049,  ...,  0.4678,  0.4503,  0.4503],\n",
              "           [ 0.1702,  0.1702,  0.1702,  ...,  0.4503,  0.4503,  0.4503]],\n",
              " \n",
              "          [[-0.6193, -0.6018, -0.4101,  ...,  2.5877,  2.5703,  2.5529],\n",
              "           [-0.5321, -0.5844, -0.4101,  ...,  2.4134,  2.3960,  2.3263],\n",
              "           [-0.4450, -0.5321, -0.3927,  ...,  1.7511,  1.4548,  1.7685],\n",
              "           ...,\n",
              "           [ 0.0605,  0.0779,  0.0779,  ...,  0.6705,  0.6705,  0.6531],\n",
              "           [ 0.2173,  0.2173,  0.2173,  ...,  0.6705,  0.6705,  0.6356],\n",
              "           [ 0.3742,  0.3742,  0.3742,  ...,  0.6531,  0.6531,  0.6356]]]]),\n",
              " tensor([[0.4422, 0.8949, 0.0833, 0.0417],\n",
              "         [0.3750, 0.8352, 0.0573, 0.0204],\n",
              "         [0.3716, 0.8593, 0.2641, 0.2444],\n",
              "         [0.3122, 0.9708, 0.1057, 0.0583],\n",
              "         [0.5237, 0.8681, 0.0411, 0.0713],\n",
              "         [0.2836, 0.8505, 0.2266, 0.0306],\n",
              "         [0.8474, 0.9153, 0.1469, 0.1694],\n",
              "         [0.3109, 0.8194, 0.1521, 0.1019],\n",
              "         [0.4391, 0.8407, 0.0792, 0.0963],\n",
              "         [0.6424, 0.9190, 0.4453, 0.1380],\n",
              "         [0.6255, 0.9495, 0.3688, 0.0361],\n",
              "         [0.1146, 0.8722, 0.2125, 0.1630],\n",
              "         [0.8940, 0.8366, 0.2120, 0.1046],\n",
              "         [0.4740, 0.7167, 0.0844, 0.0444],\n",
              "         [0.6292, 0.8546, 0.0885, 0.2907],\n",
              "         [0.7839, 0.6907, 0.1594, 0.2370],\n",
              "         [0.7305, 0.7208, 0.2453, 0.0361],\n",
              "         [0.5487, 0.7491, 0.0776, 0.0296],\n",
              "         [0.7135, 0.8597, 0.1271, 0.2787],\n",
              "         [0.4234, 0.7722, 0.0833, 0.0537],\n",
              "         [0.8247, 0.7134, 0.1661, 0.0176],\n",
              "         [0.8102, 0.8069, 0.1672, 0.0417],\n",
              "         [0.6865, 0.5440, 0.1844, 0.0306],\n",
              "         [0.6815, 0.7736, 0.0745, 0.0324],\n",
              "         [0.6771, 0.9509, 0.4167, 0.0574],\n",
              "         [0.6151, 0.8912, 0.0344, 0.1250],\n",
              "         [0.7635, 0.8620, 0.0948, 0.2278],\n",
              "         [0.5698, 0.9833, 0.0688, 0.0333],\n",
              "         [0.8372, 0.5431, 0.2318, 0.1120],\n",
              "         [0.6357, 0.7519, 0.2307, 0.0852],\n",
              "         [0.4078, 0.7093, 0.0542, 0.0259],\n",
              "         [0.4081, 0.6556, 0.0776, 0.2981]]),\n",
              " tensor([2, 2, 0, 0, 1, 2, 3, 0, 0, 0, 2, 3, 0, 0, 3, 3, 2, 0, 1, 0, 2, 0, 0, 0,\n",
              "         2, 3, 3, 0, 1, 0, 0, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, coordinates, labels in train_loader:\n",
        "        images = images.to(torch.device(\"cpu\"))\n",
        "        coordinates = coordinates.to(torch.device(\"cpu\"))\n",
        "        labels = labels.to(torch.device(\"cpu\"))\n",
        "\n",
        "        outputs = model(images, coordinates)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f\"Epoch: {epoch}, loss: {loss}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "NVcY8d2W-7P9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d47e9c4-ed83-47eb-9455-895b9ed7531e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 1.3808602094650269\n",
            "Epoch: 0, loss: 1.9254025220870972\n",
            "Epoch: 0, loss: 1.481019377708435\n",
            "Epoch: 0, loss: 1.3822617530822754\n",
            "Epoch: 0, loss: 1.3485584259033203\n",
            "Epoch: 0, loss: 1.2332817316055298\n",
            "Epoch: 0, loss: 1.334702491760254\n",
            "Epoch: 0, loss: 1.4345779418945312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/kaggle/input/road-damage\"\n",
        "image_files, text_files = load_data(path)\n",
        "\n",
        "if image_files and text_files:\n",
        "    image_path = image_files[0]\n",
        "    txt_path = text_files[0]\n",
        "\n",
        "    image_tensor = process_image(image_path)\n",
        "    class_id, coordinates = extract_damage_info(txt_path)\n",
        "\n",
        "    if coordinates is not None:\n",
        "        coordinates_tensor = torch.tensor(coordinates, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            class_output = model(image_tensor, coordinates_tensor)\n",
        "            predicted_class = torch.argmax(class_output, dim=1).item()\n",
        "            print(f\"Predicted class: {predicted_class}\")\n",
        "    else:\n",
        "        print(f\"Error reading coordinates from {txt_path}\")\n",
        "else:\n",
        "    print(\"No image or text files found in the dataset.\")\n"
      ],
      "metadata": {
        "id": "GoOKnCMV44sn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda05ed4-77b4-4988-d2f0-d26da059e191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    }
  ]
}